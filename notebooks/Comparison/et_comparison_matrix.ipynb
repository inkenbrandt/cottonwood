{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7414a9d0",
   "metadata": {},
   "source": [
    "\n",
    "# Time-Series Comparison Matrix for ET Estimates\n",
    "\n",
    "This notebook builds pairwise comparison matrices for multiple daily time series contained in a pandas `DataFrame` named **`df`** (datetime index; columns are different ET estimates).\n",
    "\n",
    "**Outputs**\n",
    "- Symmetric matrices for: RMSE, MAE, Pearson *r*, Spearman *ρ*, NSE, KGE, DTW (on z-scored series).\n",
    "- Asymmetric outputs for lead/lag analysis: a matrix of **lag at maximum correlation** (in days) and the corresponding **maximum correlation** value.\n",
    "- Optional CSV export of each matrix.\n",
    "\n",
    "**Notes**\n",
    "- By default, *shape* metrics (correlation, DTW) can be computed on z-scored series (configurable).\n",
    "- RMSE/MAE/NSE/KGE are computed on raw values (units preserved).\n",
    "- Missing values are handled pairwise per comparison.\n",
    "- DTW is O(n²); a Sakoe–Chiba window (e.g., ±30 days) is recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0be021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1) Imports & configuration ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Matplotlib defaults for clarity\n",
    "plt.rcParams['figure.figsize'] = (7, 5)\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "\n",
    "# If you want to display more decimals:\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "# ---- USER: ensure `df` is defined in the next cell, or load it from disk ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7068f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2) Provide or load your DataFrame `df` here ---------------------------------\n",
    "# REQUIREMENTS:\n",
    "# - Daily datetime index (pd.DatetimeIndex) and sorted.\n",
    "# - Columns are the ET estimates you want to compare.\n",
    "\n",
    "# EXAMPLE: Uncomment and adapt if you need a quick template for reading a CSV.\n",
    "# csv_path = \"path/to/your_daily_dataframe.csv\"\n",
    "# df = pd.read_csv(csv_path, parse_dates=[0], index_col=0)  # assumes first col is date\n",
    "# df = df.sort_index()\n",
    "\n",
    "# If you're working in a notebook where df already exists, you can skip this cell.\n",
    "\n",
    "# OPTIONAL: Quickly simulate data (comment this block out in production)\n",
    "# rng = pd.date_range(\"2023-01-01\", \"2023-12-31\", freq=\"D\")\n",
    "# rng.name = \"date\"\n",
    "# np.random.seed(42)\n",
    "# df = pd.DataFrame({\n",
    "#     \"ensemble-ET\": 3 + np.sin(np.linspace(0, 10*np.pi, len(rng))) + np.random.normal(0, 0.2, len(rng)),\n",
    "#     \"etDis\":       3.2 + np.sin(np.linspace(0.1, 10.1*np.pi, len(rng))) + np.random.normal(0, 0.2, len(rng)),\n",
    "#     \"etEns\":       2.8 + np.sin(np.linspace(-0.2, 9.8*np.pi, len(rng))) + np.random.normal(0, 0.25, len(rng)),\n",
    "#     \"etPTJ\":       3.0 + 0.9*np.sin(np.linspace(0, 10*np.pi, len(rng))) + np.random.normal(0, 0.3, len(rng)),\n",
    "#     \"etSSE\":       3.1 + 1.1*np.sin(np.linspace(0.2, 10.2*np.pi, len(rng))) + np.random.normal(0, 0.2, len(rng)),\n",
    "#     \"eteeM\":       3.05 + np.sin(np.linspace(0, 10*np.pi, len(rng))) + np.random.normal(0, 0.2, len(rng)),\n",
    "#     \"actual_et_mean\": 3.0 + np.sin(np.linspace(0, 10*np.pi, len(rng))) + np.random.normal(0, 0.25, len(rng)),\n",
    "# }, index=rng)\n",
    "# df.index.name = \"date\"\n",
    "\n",
    "# Optionally restrict to the ET columns of interest:\n",
    "et_cols = ['ensemble-ET','etDis','etEns','etPTJ','etSSE','eteeM','actual_et_mean']\n",
    "# et_cols = [c for c in et_cols if c in df.columns]  # uncomment after `df` is defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3) Metric primitives (pairwise-safe) ----------------------------------------\n",
    "\n",
    "def _pairwise_valid(a, b):\n",
    "    \"\"\"Return arrays with NaN/inf removed pairwise.\"\"\"\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    return a[mask], b[mask]\n",
    "\n",
    "def rmse(a, b):\n",
    "    a, b = _pairwise_valid(np.asarray(a), np.asarray(b))\n",
    "    return float(np.sqrt(np.mean((a - b)**2))) if a.size else np.nan\n",
    "\n",
    "def mae(a, b):\n",
    "    a, b = _pairwise_valid(np.asarray(a), np.asarray(b))\n",
    "    return float(np.mean(np.abs(a - b))) if a.size else np.nan\n",
    "\n",
    "def pearson_r(a, b):\n",
    "    a, b = _pairwise_valid(np.asarray(a), np.asarray(b))\n",
    "    if a.size < 2:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(a, b)[0,1])\n",
    "\n",
    "def spearman_r(a, b):\n",
    "    a, b = _pairwise_valid(np.asarray(a), np.asarray(b))\n",
    "    if a.size < 2:\n",
    "        return np.nan\n",
    "    return float(stats.spearmanr(a, b, nan_policy='omit').correlation)\n",
    "\n",
    "def nse(obs, sim):\n",
    "    o, s = _pairwise_valid(np.asarray(obs), np.asarray(sim))\n",
    "    if o.size < 2:\n",
    "        return np.nan\n",
    "    denom = np.sum((o - np.mean(o))**2)\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return float(1 - np.sum((o - s)**2) / denom)\n",
    "\n",
    "def kge(obs, sim):\n",
    "    o, s = _pairwise_valid(np.asarray(obs), np.asarray(sim))\n",
    "    if o.size < 2:\n",
    "        return np.nan\n",
    "    r = np.corrcoef(o, s)[0,1]\n",
    "    beta = np.mean(s) / np.mean(o) if np.mean(o) != 0 else np.nan\n",
    "    cv_o = np.std(o, ddof=1) / np.mean(o) if np.mean(o) != 0 else np.nan\n",
    "    cv_s = np.std(s, ddof=1) / np.mean(s) if np.mean(s) != 0 else np.nan\n",
    "    gamma = (cv_s / cv_o) if (cv_o not in [0, np.nan]) else np.nan\n",
    "    return float(1 - np.sqrt((r-1)**2 + (beta-1)**2 + (gamma-1)**2))\n",
    "\n",
    "def best_lag_corr(a, b, max_lag=30):\n",
    "    \"\"\"Return (lag_in_days, correlation_at_that_lag).\n",
    "    Positive lag means: b lags a (i.e., a leads).\n",
    "    Uses pairwise-valid overlap per lag.\"\"\"\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "    best_corr = -np.inf\n",
    "    best_lag = 0\n",
    "    found = False\n",
    "    for lag in range(-max_lag, max_lag+1):\n",
    "        if lag < 0:\n",
    "            # shift b forward relative to a\n",
    "            a_slice = a[-lag:]\n",
    "            b_slice = b[:len(b)+lag]\n",
    "        elif lag > 0:\n",
    "            # shift a forward relative to b\n",
    "            a_slice = a[:len(a)-lag]\n",
    "            b_slice = b[lag:]\n",
    "        else:\n",
    "            a_slice = a\n",
    "            b_slice = b\n",
    "        if len(a_slice) < 2:\n",
    "            continue\n",
    "        aa, bb = _pairwise_valid(a_slice, b_slice)\n",
    "        if aa.size < 2:\n",
    "            continue\n",
    "        r = np.corrcoef(aa, bb)[0,1]\n",
    "        if np.isfinite(r) and r > best_corr:\n",
    "            best_corr = r\n",
    "            best_lag = lag\n",
    "            found = True\n",
    "    if not found:\n",
    "        return np.nan, np.nan\n",
    "    return int(best_lag), float(best_corr)\n",
    "\n",
    "def dtw_distance(x, y, window=None):\n",
    "    \"\"\"DTW distance with optional Sakoe–Chiba window (in samples/days for daily data).\n",
    "    Uses squared Euclidean local cost and returns sqrt of total cost for scale awareness.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    # Drop pairwise NaNs up-front (strict intersection); conservative but simple.\n",
    "    xx, yy = _pairwise_valid(x, y)\n",
    "    n, m = len(xx), len(yy)\n",
    "    if n == 0 or m == 0:\n",
    "        return np.nan\n",
    "    D = np.full((n+1, m+1), np.inf)\n",
    "    D[0, 0] = 0.0\n",
    "    for i in range(1, n+1):\n",
    "        j_min = 1 if window is None else max(1, i - window)\n",
    "        j_max = m if window is None else min(m, i + window)\n",
    "        for j in range(j_min, j_max+1):\n",
    "            cost = (xx[i-1] - yy[j-1])**2\n",
    "            D[i, j] = cost + min(D[i-1, j], D[i, j-1], D[i-1, j-1])\n",
    "    return float(np.sqrt(D[n, m]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9733a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4) Driver: build comparison matrices ----------------------------------------\n",
    "\n",
    "def compare_series(df, columns, max_lag=30, dtw_window=30, z_for_shape=True, save_csv=False, out_dir=None):\n",
    "    \"\"\"Compute pairwise comparison matrices for selected columns in df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Daily time series with a DatetimeIndex; columns are ET estimates.\n",
    "    columns : list[str]\n",
    "        Subset of df columns to compare.\n",
    "    max_lag : int, default 30\n",
    "        Max absolute lag (in days) to search for best-lag correlation.\n",
    "    dtw_window : int or None, default 30\n",
    "        Sakoe–Chiba window (±window) for DTW in days/samples. Use None for unconstrained.\n",
    "    z_for_shape : bool, default True\n",
    "        If True, compute Pearson/Spearman/DTW on z-scored versions (shape-focused).\n",
    "    save_csv : bool, default False\n",
    "        If True, saves each matrix as CSV in out_dir.\n",
    "    out_dir : str or Path, optional\n",
    "        Destination directory for CSVs if save_csv is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, pandas.DataFrame]\n",
    "        A dictionary of matrices keyed by metric names.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_index()\n",
    "    # Ensure daily frequency (doesn't fill gaps; assumes input is already daily or nearly so)\n",
    "    # If you want strict daily alignment with interpolation, do it explicitly before calling.\n",
    "\n",
    "    cols = [c for c in columns if c in df.columns]\n",
    "    if len(cols) < 2:\n",
    "        raise ValueError(\"Need at least two valid columns to compare.\")\n",
    "    X = df[cols]\n",
    "\n",
    "    # Z-score version for shape metrics if requested\n",
    "    if z_for_shape:\n",
    "        Xz = (X - X.mean()) / X.std(ddof=1)\n",
    "    else:\n",
    "        Xz = X.copy()\n",
    "\n",
    "    n = len(cols)\n",
    "    idx = pd.Index(cols, name=\"series\")\n",
    "\n",
    "    # Initialize matrices\n",
    "    RMSE   = pd.DataFrame(np.nan, index=idx, columns=idx)\n",
    "    MAE    = pd.DataFrame(np.nan, index=idx, columns=idx)\n",
    "    PEAR   = pd.DataFrame(np.nan, index=idx, columns=idx)  # Pearson r\n",
    "    SPEAR  = pd.DataFrame(np.nan, index=idx, columns=idx)  # Spearman rho\n",
    "    NSEm   = pd.DataFrame(np.nan, index=idx, columns=idx)\n",
    "    KGEm   = pd.DataFrame(np.nan, index=idx, columns=idx)\n",
    "    LAG    = pd.DataFrame(np.nan, index=idx, columns=idx)  # best lag (days), sign: col_j lags col_i if +lag\n",
    "    R_AT_LAG = pd.DataFrame(np.nan, index=idx, columns=idx)  # max correlation at that lag\n",
    "    DTWm   = pd.DataFrame(np.nan, index=idx, columns=idx)  # DTW on z-scored series if z_for_shape\n",
    "\n",
    "    # Compute pairwise\n",
    "    for i, ci in enumerate(cols):\n",
    "        for j, cj in enumerate(cols):\n",
    "            if j < i:\n",
    "                # fill symmetry from previously computed value where applicable\n",
    "                RMSE.loc[ci, cj] = RMSE.loc[cj, ci]\n",
    "                MAE.loc[ci, cj]  = MAE.loc[cj, ci]\n",
    "                PEAR.loc[ci, cj] = PEAR.loc[cj, ci]\n",
    "                SPEAR.loc[ci, cj]= SPEAR.loc[cj, ci]\n",
    "                NSEm.loc[ci, cj] = NSEm.loc[cj, ci]\n",
    "                KGEm.loc[ci, cj] = KGEm.loc[cj, ci]\n",
    "                DTWm.loc[ci, cj] = DTWm.loc[cj, ci]\n",
    "                # Asymmetric metrics (lag) are not symmetric; compute both directions\n",
    "                continue\n",
    "\n",
    "            xi = X[ci].to_numpy()\n",
    "            xj = X[cj].to_numpy()\n",
    "            xi_z = Xz[ci].to_numpy()\n",
    "            xj_z = Xz[cj].to_numpy()\n",
    "\n",
    "            # Units-based (raw)\n",
    "            RMSE.loc[ci, cj] = rmse(xi, xj)\n",
    "            MAE.loc[ci, cj]  = mae(xi, xj)\n",
    "            NSEm.loc[ci, cj] = nse(xi, xj)     # treat ci as \"obs\", cj as \"sim\"\n",
    "            KGEm.loc[ci, cj] = kge(xi, xj)     # same convention\n",
    "\n",
    "            # Shape-based (z if requested)\n",
    "            PEAR.loc[ci, cj]  = pearson_r(xi_z, xj_z)\n",
    "            SPEAR.loc[ci, cj] = spearman_r(xi_z, xj_z)\n",
    "\n",
    "            # Best lag & correlation (computed on z-scored for stability)\n",
    "            lag, rmax = best_lag_corr(xi_z, xj_z, max_lag=max_lag)\n",
    "            LAG.loc[ci, cj] = lag\n",
    "            R_AT_LAG.loc[ci, cj] = rmax\n",
    "\n",
    "            # DTW (z-scored)\n",
    "            DTWm.loc[ci, cj] = dtw_distance(xi_z, xj_z, window=dtw_window)\n",
    "\n",
    "    # Mirror symmetric parts\n",
    "    RMSE = RMSE.combine_first(RMSE.T)\n",
    "    MAE  = MAE.combine_first(MAE.T)\n",
    "    PEAR = PEAR.combine_first(PEAR.T)\n",
    "    SPEAR= SPEAR.combine_first(SPEAR.T)\n",
    "    NSEm = NSEm.combine_first(NSEm.T)\n",
    "    KGEm = KGEm.combine_first(KGEm.T)\n",
    "    DTWm = DTWm.combine_first(DTWm.T)\n",
    "\n",
    "    matrices = {\n",
    "        \"RMSE\": RMSE, \"MAE\": MAE, \"Pearson_r(z)\": PEAR, \"Spearman_rho(z)\": SPEAR,\n",
    "        \"NSE(ci as obs, cj as sim)\": NSEm,\n",
    "        \"KGE(ci as obs, cj as sim)\": KGEm,\n",
    "        \"Lag_at_max_r(z) [days]\": LAG,\n",
    "        \"Max_r_at_lag(z)\": R_AT_LAG,\n",
    "        \"DTW_distance(z)\": DTWm,\n",
    "    }\n",
    "\n",
    "    if save_csv:\n",
    "        import os\n",
    "        out_dir = os.fspath(out_dir or \".\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        for name, M in matrices.items():\n",
    "            M.to_csv(os.path.join(out_dir, f\"{name.replace(' ', '_').replace('/', '_')}.csv\"))\n",
    "\n",
    "    return matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91614236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5) Example usage -------------------------------------------------------------\n",
    "# Ensure `df` and `et_cols` exist (see earlier cell). Then run:\n",
    "#\n",
    "# matrices = compare_series(\n",
    "#     df=df,\n",
    "#     columns=et_cols,\n",
    "#     max_lag=30,       # days to search for best lag\n",
    "#     dtw_window=30,    # DTW Sakoe–Chiba window (None for unconstrained; slower)\n",
    "#     z_for_shape=True, # z-score for correlation & DTW\n",
    "#     save_csv=False,   # set True to write CSVs\n",
    "#     out_dir=\"./et_matrices\"\n",
    "# )\n",
    "#\n",
    "# # Access individual matrices:\n",
    "# matrices[\"RMSE\"]\n",
    "# matrices[\"Pearson_r(z)\"]\n",
    "# matrices[\"Lag_at_max_r(z) [days]\"]\n",
    "# matrices[\"DTW_distance(z)\"]\n",
    "#\n",
    "# # Display as heatmaps (one figure per matrix):\n",
    "# for name, M in matrices.items():\n",
    "#     plt.figure()\n",
    "#     plt.imshow(M.values, origin='upper', interpolation='nearest')\n",
    "#     plt.title(name)\n",
    "#     plt.xticks(range(len(M.columns)), M.columns, rotation=45, ha='right')\n",
    "#     plt.yticks(range(len(M.index)), M.index)\n",
    "#     plt.colorbar()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
